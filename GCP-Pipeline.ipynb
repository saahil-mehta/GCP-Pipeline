{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f959fd41",
   "metadata": {},
   "source": [
    "# GCP Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9738958",
   "metadata": {},
   "source": [
    "## In essence, the pipeline goes like this:\n",
    "## Platform data -> Uploaded to an URL -> Cloud Function reads the file from URL and executes the code to ingest it -> The file is stored in GCS -> It is unzipped -> Exported to BQ as a table under the respective dataset name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1c0ef9",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fcc52b",
   "metadata": {},
   "source": [
    "## The respective platform drops data (name:Self_active_subscribers2022-06-13T23_00_00.000Z.zip) onto the Cloud Function URL, this URL is assigned as the trigger for the function to start working. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a535b3",
   "metadata": {},
   "source": [
    "## The file (zip) is uploaded to the bucket called \"platform_daily_active_file\", this is performed by code #1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc556bf",
   "metadata": {},
   "source": [
    "## However, the zip file needs to be unzipped to be ingested. The code #2 does exactly that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e3ea06",
   "metadata": {},
   "source": [
    "## The #3 part of the code, defines a schema in BigQuery and uploads the unzipped file as a BQ table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42b843b",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1eaead",
   "metadata": {},
   "source": [
    "## #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9c2944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function dependencies, for example:\n",
    "# package>=version\n",
    "google-cloud-storage\n",
    "requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfe5452",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import requests\n",
    "\n",
    "def csg_upload_subscriber(request) :\n",
    "    request_json = request.get_json(silent=True)\n",
    "        \n",
    "    export_location = request_json[\"ExportLocation\"]\n",
    "    name = \"Self_active_subscribers\" + request_json[\"StartDate\"] + \".zip\"\n",
    "    \n",
    "    project_id = 'xx-x-xxx'\n",
    "    client = storage.Client(project=project_id)\n",
    "    bucket = client.get_bucket('platform_daily_active_file')\n",
    "\n",
    "    CSG_File = requests.get(export_location)\n",
    "\n",
    "    blob = bucket.blob(name)\n",
    "    blob.upload_from_string(CSG_File.content, \"application/zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8185c2fd",
   "metadata": {},
   "source": [
    "## #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85ca706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# requirements.txt\n",
    "# Function dependencies, for example:\n",
    "# package>=version\n",
    "google-cloud-storage\n",
    "zipfile36\n",
    "regex\n",
    "pandas-io\n",
    "pyzipper\n",
    "pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3576a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "from zipfile36 import ZipFile\n",
    "from zipfile36 import is_zipfile\n",
    "import pyzipper\n",
    "import regex as re\n",
    "import io\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "\n",
    "def unzip_file(\n",
    "    event,\n",
    "    context,\n",
    "    ):\n",
    "    \n",
    "    print(\"here\")\n",
    "    print(event)\n",
    "    print(event[\"name\"])\n",
    "\n",
    "    client2 = storage.Client()\n",
    "\n",
    "    file = event\n",
    "    bucket = client2.get_bucket(\"platform_daily_active_file\")\n",
    "    source_file = file[\"name\"]\n",
    "    metaGeneration = file[\"metageneration\"]\n",
    "    contentType = file[\"contentType\"]\n",
    "\n",
    "    if metaGeneration == \"1\" and contentType == \"application/zip\":\n",
    "        blob = bucket.get_blob(source_file)\n",
    "        zipbytes = io.BytesIO(blob.download_as_string())\n",
    "        if is_zipfile(zipbytes):\n",
    "            with pyzipper.AESZipFile(zipbytes, \"r\") as zip:\n",
    "                zip.pwd = b\"pass@123\"\n",
    "                fname = zip.namelist()[0]\n",
    "                imgdata = zip.read(fname)\n",
    "                text = imgdata.decode(\"utf-8\")\n",
    "\n",
    "                myreader = csv.reader(text.splitlines())\n",
    "                list = []\n",
    "                for row in myreader:\n",
    "                    list.append(row[0:])\n",
    "                df = pd.DataFrame(list)\n",
    "                headers = df.iloc[0]\n",
    "                df_final = pd.DataFrame(list[1:], columns=headers)\n",
    "\n",
    "                blob = bucket.blob(fname)\n",
    "                blob.upload_from_string(df_final.to_csv(index=False), 'text/csv')\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6092ddb",
   "metadata": {},
   "source": [
    "## #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46468b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function dependencies, for example:\n",
    "# package>=version\n",
    "google-cloud-bigquery\n",
    "google-cloud-storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc3712f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "from google.cloud import bigquery\n",
    "\n",
    "def  csg_subscriber_upload(event, context):\n",
    "    print(\"step 1\")\n",
    "    file = event\n",
    "    print (file)\n",
    "    source_file = str(file['name'])\n",
    "    print (source_file)\n",
    "    uri = 'gs://platform_daily_active_file/' + source_file\n",
    "    contentType = file['contentType']\n",
    "\n",
    "    if (contentType == 'text/csv'):\n",
    "        print(\"step 1\")\n",
    "        dataset = 'client_platform'\n",
    "        table = 'Platform_Subscribers_Info' + source_file.split('_')[1] \\\n",
    "            + source_file.split('_')[2] + source_file.split('_')[3]\n",
    "        print (table)\n",
    "        bigquery_client = bigquery.Client()\n",
    "        dataset_ref = bigquery_client.dataset(dataset)\n",
    "        job_config = bigquery.LoadJobConfig()\n",
    "        job_config.autodetect = True\n",
    "        #job_config.schema_update_options = \\\n",
    "            #[bigquery.SchemaUpdateOption.ALLOW_FIELD_ADDITION]\n",
    "        job_config.create_disposition = \\\n",
    "            bigquery.job.CreateDisposition.CREATE_IF_NEEDED\n",
    "        job_config.write_disposition = \\\n",
    "            bigquery.WriteDisposition.WRITE_TRUNCATE\n",
    "        load_job = bigquery_client.load_table_from_uri(uri,\n",
    "                dataset_ref.table(table), job_config=job_config)\n",
    "        load_job.result()\n",
    "        destination_table = \\\n",
    "            bigquery_client.get_table(dataset_ref.table(table))\n",
    "        print (file['name'])\n",
    "        print ('Loaded {} rows.'.format(destination_table.num_rows))\n",
    "        print ('Data uploaded into BigQuery table successfully.')\n",
    "\n",
    "    else:\n",
    "        print ('Not a CSV File')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986f8bd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9218e10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0bc398",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a747793e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
